import { getModel } from "@/src/contents/utils";
import Anthropic from "@anthropic-ai/sdk";
import { PromptTemplate } from "@langchain/core/prompts";
import { FakeListChatModel } from "@langchain/core/utils/testing";
import { LangChainAdapter } from "ai";

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY!,
});

/** YES/NO ã‚’ç­”ãˆã•ã›ã‚‹é–¢æ•° */
async function getYesNoResponse(question: string, questionType: string) {
  const response = await anthropic.messages.create({
    model: "claude-3-5-haiku-latest",
    max_tokens: 10,
    messages: [
      {
        role: "user",
        content: `${question}\nã“ã®æ–‡ç« ã¯ ${questionType} ã§ã™ã‹ï¼ŸYES ã¾ãŸã¯ NO ã®ã©ã¡ã‚‰ã‹ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`,
      },
    ],
  });

  const textBlock = response.content.find((block) => block.type === "text");
  return textBlock?.text?.trim().toUpperCase() || "";
}

/** APIã‹ã‚‰çµæœã‚’å–å¾— */
async function getResult(api: string, messages: any, modelName: any) {
  const res = await fetch(api, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
    },
    body: JSON.stringify({ messages, model: modelName }),
  });
  return await res.json();
}

/**
 * ä¼šè©±åˆ¤æ–­ç”¨AI
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];
    const modelName = body.model ?? "fake-llm";

    /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    const currentMessageContent = messages[messages.length - 1].content;

    /** æ‚©ã¿ç›¸è«‡ */
    const concernsAnswer = await getYesNoResponse(
      currentMessageContent,
      "æ‚©ã¿ã‚„ä¸å®‰ã‹ã‚‰ãã¦ã„ã‚‹ç›¸è«‡"
    );
    console.log("ğŸ§  æ‚©ã¿: " + concernsAnswer);

    /** æŒ‡ç¤º */
    const instructionAnswer = await getYesNoResponse(
      currentMessageContent,
      "AIã«å¯¾ã™ã‚‹æŒ‡ç¤º"
    );
    console.log("ğŸ§  æŒ‡ç¤º: " + instructionAnswer);

    /** å›ç­”ã®èãå‡ºã— */
    let response = null;
    if (concernsAnswer === "YES") {
      response = await getResult(
        "http://localhost:3000/api/mentor",
        messages,
        modelName
      );
    } else if (instructionAnswer === "YES") {
      response = await getResult(
        "http://localhost:3000/api/mcp-client",
        messages,
        modelName
      );
    } else {
      response = await getResult(
        "http://localhost:3000/api/chat",
        messages,
        modelName
      );
    }

    /**
     * ãƒ•ã‚§ã‚¤ã‚¯ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€å¿œç­”ã‚’ç”Ÿæˆ
     */
    const fakeModel = new FakeListChatModel({
      responses: [
        response ? response.kwargs.content : "æ‚©ã¿ç›¸è«‡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
      ],
    });
    const prompt = PromptTemplate.fromTemplate(
      `system: ä»¥ä¸‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…ƒã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\nAI: {ai_input}\nuser: {user_input}\nAI: `
    );
    const model = getModel(modelName);

    const chain = prompt.pipe(model);
    const stream = await chain.stream({
      ai_input: response ? response.kwargs.content : "æ‚©ã¿ç›¸è«‡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
      user_input: currentMessageContent,
    });

    return LangChainAdapter.toDataStreamResponse(stream);
  } catch (error) {
    if (error instanceof Error) {
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
