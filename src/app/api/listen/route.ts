import { Model } from "@/src/contents/type";
import { getModel } from "@/src/contents/utils";
import Anthropic from "@anthropic-ai/sdk";
import { ChatMessage } from "@langchain/core/messages";
import { ParamsFromFString, PromptTemplate } from "@langchain/core/prompts";
import { Message as VercelChatMessage, LangChainAdapter } from "ai";
import { Client } from "langsmith";

// å®šæ•°
const ANTHROPIC_MODEL_3 = "claude-3-haiku-20240307";

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY!,
});

const client = new Client({
  apiKey: process.env.LANGSMITH_API_KEY,
});

// ç›¸è«‡ä¸­ã®ãƒ•ãƒ©ã‚°
let hasConcerns = false;
let wasConcerns = false;

/** YES/NO ã‚’ç­”ãˆã•ã›ã‚‹é–¢æ•° */
async function getYesNoResponse(question: string, questionType: string) {
  const response = await anthropic.messages.create({
    model: ANTHROPIC_MODEL_3,
    max_tokens: 10,
    temperature: 0,
    messages: [
      {
        role: "user",
        content: `${question}\nã“ã®æ–‡ç« ã¯ ${questionType} ã§ã™ã‹ï¼ŸYES ã¾ãŸã¯ NO ã®ã©ã¡ã‚‰ã‹ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`,
      },
    ],
  });

  const textBlock = response.content.find((block) => block.type === "text");
  return textBlock?.text?.trim().toUpperCase() || "";
}

/** APIã‹ã‚‰çµæœã‚’å–å¾— */
async function getResult(
  api: string,
  messages: ChatMessage[],
  modelName: Model
) {
  const res = await fetch(api, {
    method: "POST",
    credentials: "include",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${process.env.ACCESS_TOKEN}`,
    },
    body: JSON.stringify({ messages, model: modelName }),
  });

  const body = await res.json();
  if (!res.ok) {
    const errorBody = body.catch(() => null);
    if (errorBody && errorBody.message) {
      throw new Error(`API error: ${errorBody.message}`);
    }

    // JSONã§ãªã‘ã‚Œã°ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    const text = body.text();
    throw new Error(`API error: ${text || res.statusText}`);
  }

  return body;
}

/**
 * ä¼šè©±åˆ¤æ–­ç”¨AI
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];
    const modelName = body.model ?? "fake-llm";

    // ãƒ‘ã‚¹
    const host = req.headers.get("host");
    const protocol = host?.includes("localhost") ? "http" : "https";
    const baseUrl = `${protocol}://${host}`;

    console.log("API: " + baseUrl);

    /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    const formatMessage = (message: VercelChatMessage) => {
      return `${message.role}: ${message.content}`;
    };
    const formattedPreviousMessages = messages.slice(0, -1).map(formatMessage);
    const currentMessageContent = messages[messages.length - 1].content;

    /** æ‚©ã¿ç›¸è«‡ */
    const concernsAnswer = await getYesNoResponse(
      currentMessageContent,
      "æ‚©ã¿ã‚„ä¸å®‰ã‹ã‚‰ãã¦ã„ã‚‹ç›¸è«‡"
    );
    console.log("ğŸ’› æ‚©ã¿: " + concernsAnswer + " ãƒ•ãƒ©ã‚°: " + hasConcerns);

    /** æŒ‡ç¤º */
    const instructionAnswer = await getYesNoResponse(
      currentMessageContent,
      "AIã«å¯¾ã™ã‚‹æŒ‡ç¤ºã‚„æ¨™æº–ã®AIã§ã¯è§£æ±ºã§ããªã„å•é¡Œ"
    );
    console.log("ğŸ”¨ æŒ‡ç¤º: " + instructionAnswer);

    /** å›ç­”ã®èãå‡ºã— */
    let response = null;
    if (concernsAnswer === "YES" || hasConcerns) {
      hasConcerns = true;
      response = await getResult(baseUrl + "/api/mentor", messages, modelName);

      // ä¼šè©±ãŒçµ‚ã‚ã£ãŸã“ã¨ã‚’åˆ¤æ–­ã™ã‚‹
      const resText = response ? response.kwargs.content : "";
      if (resText.includes("--ç›¸è«‡ã®çµ‚äº†--")) {
        console.log("ğŸ’› ãŠæ‚©ã¿ç›¸è«‡ã®çµ‚äº†");
        hasConcerns = false;
      }
    } else if (instructionAnswer === "YES") {
      response = await getResult(
        baseUrl + "/api/mcp-client",
        messages,
        modelName
      );
    }

    /** å¿œç­”ã‚’ä½œæˆ */
    const chatTemplate = await client.pullPromptCommit("chat-menter-charactor");
    const concernsFinishTemplate = `system:\nä»Šã¾ã§ã®ä¼šè©±ã¨ä¸‹è¨˜ã®AIã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‚è€ƒã«ã€ä¼šè©±ãŒé€”ä¸­ã§ã‚‚ä»Šã¾ã§ã®ç›¸è«‡ã‚’ç·æ‹¬ã—ã¦ãã ã•ã„ã€‚ã¾ãŸç›¸è«‡è€…ã®ã“ã‚Œã‹ã‚‰ã«ã¤ã„ã¦å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ã‚ã’ã¦ãã ã•ã„ã€‚\n\nä¼šè©±å±¥æ­´:---\n{chat_history}\n---\n\nAI: {ai_input}\n\nuser: {user_input}\nassistant: `;

    let prompt = PromptTemplate.fromTemplate(
      chatTemplate.manifest.kwargs.template
    );
    // ãŠæ‚©ã¿ç›¸è«‡ãŒã²ã¨æ®µè½ã—ãŸã‚‰ã¾ã¨ã‚ã¨ã“ã‚Œã‹ã‚‰ã‚’è¿°ã¹ã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼Ÿ
    if (!hasConcerns && wasConcerns) {
      prompt = PromptTemplate.fromTemplate(concernsFinishTemplate);
      console.log("has: " + hasConcerns + "\n" + "was: " + wasConcerns);
    }
    const model = getModel(modelName);

    const chain = prompt.pipe(model);
    const stream = await chain.stream({
      chat_history: formattedPreviousMessages.join("\n"),
      ai_input: response ? response.kwargs.content : "æ‚©ã¿ç›¸è«‡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
      user_input: currentMessageContent,
    });

    // æœ€å¾Œã®å‡¦ç†
    wasConcerns = hasConcerns;

    return LangChainAdapter.toDataStreamResponse(stream);
  } catch (error) {
    if (error instanceof Error) {
      console.log(error);
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
