import { Model } from "@/src/contents/type";
import { getModel } from "@/src/contents/utils";
import Anthropic from "@anthropic-ai/sdk";
import { ChatMessage } from "@langchain/core/messages";
import { PromptTemplate } from "@langchain/core/prompts";
import { Message as VercelChatMessage, LangChainAdapter } from "ai";
import { Client } from "langsmith";

const baseUrl = process.env.VERCEL_URL
  ? `https://${process.env.VERCEL_URL}`
  : "http://localhost:3000"; // ãƒ­ãƒ¼ã‚«ãƒ«ç”¨

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY!,
});

const ANTHROPIC_MODEL_3 = "claude-3-haiku-20240307";

const client = new Client({
  apiKey: process.env.LANGSMITH_API_KEY,
});

// ç›¸è«‡ä¸­ã®ãƒ•ãƒ©ã‚°
let hasConcerns = false;

/** YES/NO ã‚’ç­”ãˆã•ã›ã‚‹é–¢æ•° */
async function getYesNoResponse(question: string, questionType: string) {
  const response = await anthropic.messages.create({
    model: ANTHROPIC_MODEL_3,
    max_tokens: 10,
    temperature: 0,
    messages: [
      {
        role: "user",
        content: `${question}\nã“ã®æ–‡ç« ã¯ ${questionType} ã§ã™ã‹ï¼ŸYES ã¾ãŸã¯ NO ã®ã©ã¡ã‚‰ã‹ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`,
      },
    ],
  });

  const textBlock = response.content.find((block) => block.type === "text");
  return textBlock?.text?.trim().toUpperCase() || "";
}

/** APIã‹ã‚‰çµæœã‚’å–å¾— */
async function getResult(
  api: string,
  messages: ChatMessage[],
  modelName: Model
) {
  const res = await fetch(api, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
    },
    body: JSON.stringify({ messages, model: modelName }),
  });
  return await res.json();
}

/**
 * ä¼šè©±åˆ¤æ–­ç”¨AI
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];
    const modelName = body.model ?? "fake-llm";

    /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    const formatMessage = (message: VercelChatMessage) => {
      return `${message.role}: ${message.content}`;
    };
    const formattedPreviousMessages = messages.slice(0, -1).map(formatMessage);
    const currentMessageContent = messages[messages.length - 1].content;

    /** æ‚©ã¿ç›¸è«‡ */
    const concernsAnswer = await getYesNoResponse(
      currentMessageContent,
      "æ‚©ã¿ã‚„ä¸å®‰ã‹ã‚‰ãã¦ã„ã‚‹ç›¸è«‡"
    );
    console.log("ğŸ’› æ‚©ã¿: " + concernsAnswer + " ãƒ•ãƒ©ã‚°: " + hasConcerns);

    /** æŒ‡ç¤º */
    const instructionAnswer = await getYesNoResponse(
      currentMessageContent,
      "AIã«å¯¾ã™ã‚‹æŒ‡ç¤ºã‚„æ¨™æº–ã®AIã§ã¯è§£æ±ºã§ããªã„å•é¡Œ"
    );
    console.log("ğŸ”¨ æŒ‡ç¤º: " + instructionAnswer);

    /** å›ç­”ã®èãå‡ºã— */
    let response = null;
    if (concernsAnswer === "YES" || hasConcerns) {
      hasConcerns = true;
      response = await getResult(baseUrl + "/api/mentor", messages, modelName);
    } else if (instructionAnswer === "YES") {
      response = await getResult(
        baseUrl + "/api/mcp-client",
        messages,
        modelName
      );
    }

    /** å¿œç­”ã‚’ä½œæˆ */
    const chatTemplate = await client.pullPromptCommit("chat-menter-charactor");
    const prompt = PromptTemplate.fromTemplate(
      chatTemplate.manifest.kwargs.template
    );
    const model = getModel(modelName);

    const chain = prompt.pipe(model);
    const stream = await chain.stream({
      chat_history: formattedPreviousMessages.join("\n"),
      ai_input: response ? response.kwargs.content : "æ‚©ã¿ç›¸è«‡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
      user_input: currentMessageContent,
    });

    return LangChainAdapter.toDataStreamResponse(stream);
  } catch (error) {
    if (error instanceof Error) {
      console.log(error);
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
