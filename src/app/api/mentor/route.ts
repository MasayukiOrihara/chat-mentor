import { PromptTemplate } from "@langchain/core/prompts";
import { FakeListChatModel } from "@langchain/core/utils/testing";
import {
  Annotation,
  messagesStateReducer,
  StateGraph,
} from "@langchain/langgraph";
import { AIMessage, BaseMessage, HumanMessage } from "@langchain/core/messages";
import Anthropic from "@anthropic-ai/sdk";
import { MentorStates, ChecklistItem } from "@/src/contents/type";
import { loadJsonFile, UserMessage } from "@/src/contents/utils";
import { Client } from "langsmith";
import { PromptCommit } from "langsmith/schemas";

// å®šæ•°
const ANTHROPIC_MODEL_3_5 = "claude-3-5-haiku-20241022";
const ANTHROPIC_MODEL_3 = "claude-3-haiku-20240307";
const LIST_JSON_PATH = "src/data/checklist.json";
const CONSULTING_FINISH_MESSAGE = "--ç›¸è«‡ã®çµ‚äº†--\n";

// é·ç§»ã®çŠ¶æ…‹ä¿å­˜
const transitionStates: MentorStates = {
  isConsulting: false, // ãƒ¡ãƒ³ã‚¿ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã‹
  hasQuestion: true, // è³ªå•ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã‹
};

// ç¹°ã‚Šè¿”ã—ãŸå›æ•°
let count = 0;
// ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
let checklist: ChecklistItem[][];

// å…¨åˆæœŸåŒ–
function init() {
  count = 0;
  transitionStates.isConsulting = false;
  transitionStates.hasQuestion = true;
  checklist = [];
}

// anthropic ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY!,
});

// langsmithã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾—
const client = new Client({
  apiKey: process.env.LANGSMITH_API_KEY,
});

// å›ç­”ã‚’æ•´å½¢ã™ã‚‹é–¢æ•°
function formatAnthropicMessage(
  anthropicMessage: Anthropic.Messages.Message & {
    _request_id?: string | null;
  }
) {
  const textBlock = anthropicMessage.content.find(
    (block) => block.type === "text"
  );
  return textBlock?.text?.trim().toUpperCase() || "";
}

/** ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã™ã¹ã¦äº‹å‰ã«èª­ã¿è¾¼ã‚€ï¼ˆéåŒæœŸå‡¦ç†ï¼‰ */
let allPrompt: PromptCommit[];
async function loadAllPrompts() {
  // langsmithå´ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åå‰
  const promptnames = [
    "mentor_check-contenue-talk",
    "mentor_check-user-message",
    "mentor_select-next-question",
    "mentor_summarize-message",
  ];
  // èª­ã¿è¾¼ã¿é–‹å§‹
  const promises = promptnames.map((name) => client.pullPromptCommit(name));
  // å‡¦ç†å¾…ã¡
  const prompts = await Promise.all(promises);

  return prompts;
}

/**
 * ãƒãƒ¼ãƒ‰å®šç¾©
 */
/** å‰ã‚¿ãƒ¼ãƒ³ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹åˆå›ãƒãƒ¼ãƒ‰ */
async function checkPrevState() {
  console.log("ğŸ” ãƒã‚§ãƒƒã‚¯åˆå›ãƒãƒ¼ãƒ‰");
  console.log("å‰å›ã®çŠ¶æ…‹: ", transitionStates);

  //ã€€å‰å›ã®çŠ¶æ…‹ã‚’ç¢ºèª
  console.log("ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ: ", checklist);

  const intStep = Math.floor(count / 1);
  console.log(`ç›¸è«‡ã‚’å§‹ã‚ã¦ ${count} ã‚¿ãƒ¼ãƒ³ç›®`);
  console.log(`ç¾åœ¨ STEP ${intStep}`);

  if (intStep === 3) {
    transitionStates.hasQuestion = false;
  }

  // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿
  allPrompt = await loadAllPrompts();

  return {
    transition: { ...transitionStates },
    step: intStep,
  };
}

async function initSetting() {
  /** åˆæœŸè¨­å®šã‚’è¡Œã†ãƒãƒ¼ãƒ‰ */
  console.log("ğŸ”§ åˆæœŸè¨­å®šãƒãƒ¼ãƒ‰");

  init(); // åˆæœŸåŒ–(å¿µã®ãŸã‚)

  // åˆæœŸè¨­å®š
  transitionStates.isConsulting = true;

  // ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®æº–å‚™
  const readJson = await loadJsonFile<ChecklistItem[][]>(LIST_JSON_PATH);
  if (readJson.success) {
    checklist = readJson.data;
  } else {
    return new Response(JSON.stringify({ error: readJson.error }), {
      status: 500,
      headers: { "Content-type": "application/json" },
    });
  }

  return {
    transition: { ...transitionStates },
    stap: count,
  };
}

/** è³ªå•ã‚’æº–å‚™ã™ã‚‹ãƒãƒ¼ãƒ‰ */
async function prepareQuestion({
  messages,
  contexts,
}: typeof MentorAnnotation.State) {
  console.log("ğŸ“ è³ªå•æº–å‚™ãƒãƒ¼ãƒ‰");

  // 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’å–å¾—
  const userMessage = messages[messages.length - 1].content;
  console.log("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€: ", userMessage);

  // 2. ä¼šè©±ç¶™ç¶šã®æ„æ€ã‚’ç¢ºèª
  const CHECK_CONTENUE_TALK = allPrompt[0].manifest.kwargs.template.replace(
    "{user_message}",
    userMessage
  );

  const checkContenueTalk = await anthropic.messages.create({
    model: ANTHROPIC_MODEL_3_5,
    max_tokens: 2,
    temperature: 0,
    messages: UserMessage(CHECK_CONTENUE_TALK),
  });
  const resContenueTalk = formatAnthropicMessage(checkContenueTalk);
  console.log("ä¼šè©±çµ‚äº†ã®æ„æ€: " + resContenueTalk);

  // ç¶™ç¶šã®æ„æ€ãªã—ã¨åˆ¤æ–­
  if (resContenueTalk.includes("YES")) {
    transitionStates.hasQuestion = false;
    return { contexts, transition: { ...transitionStates } };
  }

  // 3. ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢
  let checklistAllText = "";
  for (const subList of checklist) {
    for (const item of subList) {
      checklistAllText +=
        "question: " +
        item.question +
        "\n" +
        "checked: " +
        item.checked +
        "\n" +
        "comment: " +
        item.comment +
        "\n --- \n";
    }
  }

  // 4. ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®è³ªå•ã¨ã®ä¸€è‡´é …ç›®ã‚’ç‰¹å®š
  const CHECK_USER_MESSAGE = allPrompt[1].manifest.kwargs.template
    .replace("{checklist_text}", checklistAllText)
    .replace("{user_message}", userMessage);

  const checkUserMessage = await anthropic.messages.create({
    model: ANTHROPIC_MODEL_3,
    max_tokens: 1000,
    temperature: 0,
    messages: UserMessage(CHECK_USER_MESSAGE),
  });
  const response = formatAnthropicMessage(checkUserMessage);
  console.log("ä¸€è‡´é …ç›®ã®å›ç­”çµæœ:\n" + response);

  // 5. JSONã«æˆ»ã™ â€» anthropicãã‚“ã®æ©Ÿå«Œã§å´©ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé€ã£ã¦ãã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚‹ã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯ã¯ã—ãŸæ–¹ãŒã„ã„
  const blocks = response
    .split("---")
    .map((block) => block.trim())
    .filter(Boolean);

  for (const item of blocks) {
    const calams = item
      .split("\n")
      .map((calam) => calam.trim())
      .filter(Boolean);

    for (const group of checklist) {
      for (const item of group) {
        if (calams[0]?.includes(item.question)) {
          item.checked = calams[1]?.toLowerCase().includes("true") ?? false;

          if (calams[2]) {
            const index = calams[2].indexOf("COMMENT: ");
            if (index !== -1) {
              item.comment =
                (item.comment ?? "") +
                calams[2].slice(index + "COMMENT: ".length) +
                ", ";
            }
          }
        }
      }
    }
  }
}

/** ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã™ã‚‹ãƒãƒ¼ãƒ‰ */
async function addContext({
  messages,
  contexts,
  step,
}: typeof MentorAnnotation.State) {
  console.log("ğŸ“š ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ ãƒãƒ¼ãƒ‰");

  const userMessage = messages[messages.length - 1].content;
  console.log("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€: ", userMessage);

  // AIã«æ¬¡ã®è³ªå•ã‚’æ¸¡ã™ç”¨ã¨ã—ã¦æ•´å½¢
  let checklistQuestion = "";
  for (const item of checklist[step]) {
    checklistQuestion += "ãƒ»" + item.question + "\n";
  }

  // ã©ã‚Œã‚’è³ªå•ã™ã‚‹ã‹ã‚’æ±ºã‚ã•ã›ã‚‹
  const SELECT_NEXT_QUESTION = allPrompt[2].manifest.kwargs.template
    .replace("{checklist_question}", checklistQuestion)
    .replace("{user_message}", userMessage);

  const selectNextQuestion = await anthropic.messages.create({
    model: ANTHROPIC_MODEL_3,
    max_tokens: 300,
    temperature: 0.5,
    messages: UserMessage(SELECT_NEXT_QUESTION),
  });
  contexts = formatAnthropicMessage(selectNextQuestion);
  console.log("contexts: " + contexts);

  return { contexts };
}

/** é€ä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’åŠ å·¥ã™ã‚‹ãƒãƒ¼ãƒ‰ */
async function buildSendData({
  messages,
  contexts,
}: typeof MentorAnnotation.State) {
  console.log("ğŸ“¤ é€ä¿¡ãƒ‡ãƒ¼ã‚¿åŠ å·¥ãƒãƒ¼ãƒ‰");

  // contextsã‚’å‡ºåŠ›
  return { messages: [...messages, new AIMessage(contexts)] };
}

/** ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ãƒãƒ¼ãƒ‰ */
async function saveData() {
  console.log("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒãƒ¼ãƒ‰");

  // ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’JSONå½¢å¼ã§ä¿å­˜ã—ãŸã„å ´åˆã¯ã“ã“ã¸
  // çµ‚äº†å‡¦ç†ã‚‚ã“ã“
  count++;
}

/** è³ªå•ãŒçµ‚äº†ã—ã¦ä»Šå›ã®è©±ã‚’ç·æ‹¬ã™ã‚‹ãƒãƒ¼ãƒ‰ */
async function summarizeConversation({
  contexts,
}: typeof MentorAnnotation.State) {
  console.log("ğŸ“¢ ç·æ‹¬ãƒãƒ¼ãƒ‰");

  // 1. ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
  let checklistAllText = "";
  for (const subList of checklist) {
    for (const item of subList) {
      checklistAllText +=
        "question: " +
        item.question +
        "\n" +
        "checked: " +
        item.checked +
        "\n" +
        "comment: " +
        item.comment +
        "\n --- \n";
    }
  }

  // 2. ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’å‚è€ƒã«ç·æ‹¬ã‚’ã™ã‚‹
  const SUMMARIZE_MESSAGE = allPrompt[3].manifest.kwargs.template.replace(
    "{checklist-text}",
    checklistAllText
  );

  const summarizeMessage = await anthropic.messages.create({
    model: ANTHROPIC_MODEL_3,
    max_tokens: 500,
    temperature: 0.5,
    messages: UserMessage(SUMMARIZE_MESSAGE),
  });
  contexts =
    CONSULTING_FINISH_MESSAGE + formatAnthropicMessage(summarizeMessage);
  console.log("ç·æ‹¬:\n" + contexts);

  // åˆæœŸåŒ–
  init();

  return { contexts };
}

/**
 * ã‚°ãƒ©ãƒ•å®šç¾©
 */
const MentorAnnotation = Annotation.Root({
  messages: Annotation<BaseMessage[]>({
    reducer: messagesStateReducer,
    default: () => [],
  }),
  contexts: Annotation<string>({
    value: (state: string = "", action: string) => state + action,
    default: () => "",
  }),
  step: Annotation<number>({
    value: (action: number) => action,
    default: () => 0,
  }),
  transition: Annotation<MentorStates>({
    value: (
      state: MentorStates = {
        isConsulting: false,
        hasQuestion: true,
      },
      action: Partial<MentorStates>
    ) => ({
      ...state,
      ...action,
    }),
  }),
});

const MentorGraph = new StateGraph(MentorAnnotation)
  .addNode("check", checkPrevState)
  .addNode("init", initSetting)
  .addNode("prepare", prepareQuestion)
  .addNode("context", addContext)
  .addNode("build", buildSendData)
  .addNode("save", saveData)
  .addNode("summary", summarizeConversation)
  .addEdge("__start__", "check")
  .addConditionalEdges("check", (state) =>
    state.transition.isConsulting ? "prepare" : "init"
  )
  .addEdge("init", "prepare")
  .addConditionalEdges("prepare", (state) =>
    state.transition.hasQuestion ? "context" : "summary"
  )
  .addEdge("context", "build")
  .addEdge("summary", "build")
  .addEdge("build", "save")
  .addEdge("save", "__end__")
  .compile();

/**
 * ãƒãƒ£ãƒƒãƒˆå¿œç­”AI
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];
    const modelName = body.model ?? "fake-llm";

    console.log("ğŸ’› ãƒ¡ãƒ³ã‚¿ãƒ¼ãƒãƒ£ãƒƒãƒˆAPI ");
    console.log("ğŸ§  ãƒ¢ãƒ‡ãƒ«: ", modelName);
    console.log("---");

    /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    const currentMessageContent = messages[messages.length - 1].content;

    /** LangGraph */
    const result = await MentorGraph.invoke({
      messages: [new HumanMessage(currentMessageContent)],
    });

    const text = result.messages[result.messages.length - 1].content.toString();
    console.log("ğŸ“ˆ LangGraph: \n" + text);

    /**
     * ãƒ•ã‚§ã‚¤ã‚¯ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ãã®ã¾ã¾å¿œç­”ã‚’é€ä¿¡
     */
    const fakeModel = new FakeListChatModel({
      responses: [text],
    });
    const fakePrompt = PromptTemplate.fromTemplate("TEMPLATE1");
    const fakeChain = fakePrompt.pipe(fakeModel);
    const fakeStream = await fakeChain.invoke({});

    //return LangChainAdapter.toDataStreamResponse(fakeStream);
    return new Response(JSON.stringify(fakeStream));
  } catch (error) {
    if (error instanceof Error) {
      console.error("API 500 error: " + error);
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
