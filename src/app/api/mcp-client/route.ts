import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { FakeListChatModel } from "@langchain/core/utils/testing";
import { PromptTemplate } from "@langchain/core/prompts";
import { Message as VercelChatMessage, LangChainAdapter } from "ai";
import { ChatOpenAI } from "@langchain/openai";
import Anthropic from "@anthropic-ai/sdk";
import { ToolUseBlock } from "@anthropic-ai/sdk/resources/messages";
import { StringOutputParser } from "@langchain/core/output_parsers";

const openAiModel = new ChatOpenAI({
  model: "gpt-4o",
  apiKey: process.env.OPENAI_API_KEY,
  temperature: 0.8,
  tags: ["mcp"],
});

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY!,
});

// å®šæ•°
const PYTHON_PATH = process.cwd() + "/mcp-server/.venv/Scripts/python.exe";
const ADD_PY_PATH = process.cwd() + "/mcp-server/add.py";
const SEARCH_PY_PATH = process.cwd() + "/mcp-server/search.py";

export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];

    /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç† */
    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ£ãƒƒãƒˆã®å–å¾—
    const current = messages[messages.length - 1];
    const formattedMessages = [
      {
        role: current.role,
        content: current.content,
      },
    ];
    // messages.slice(-1).map(formatMessage);
    console.log("âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€: ", formattedMessages);

    /**
     * é€šä¿¡å‡¦ç†
     */
    // é€šä¿¡æ–¹æ³•ã®å®šç¾©: ä»Šå›ã¯Pythonã®ã‚µãƒ¼ãƒã‚’å‚ç…§
    const transportAdd = new StdioClientTransport({
      command: PYTHON_PATH,
      args: [ADD_PY_PATH],
    });

    const transportSearch = new StdioClientTransport({
      command: PYTHON_PATH,
      args: [SEARCH_PY_PATH],
    });

    // Clientã®åˆæœŸåŒ–
    const client = new Client({
      name: "mcp-client",
      version: "1.0.0",
    });
    // await client.connect(transportAdd);
    await client.connect(transportSearch);

    /**
     * ãƒ„ãƒ¼ãƒ«é¸å®š
     */
    const listRes = await client.listTools();

    // ä½¿ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«ã®å–å¾—ï¼ˆLLMç”¨ã«æ•´å½¢ï¼‰
    const availableTools = listRes.tools.map((t) => ({
      name: t.name,
      description: t.description,
      input_schema: t.inputSchema,
    }));
    console.log(
      "âœ… Available tools:",
      availableTools.map((t) => t.name)
    );

    // anthropicã®ãƒ„ãƒ¼ãƒ«é¸å®š
    const selectTools = await anthropic.messages.create({
      model: "claude-3-5-haiku-latest",
      max_tokens: 1000,
      messages: formattedMessages,
      tools: availableTools,
    });

    console.log(selectTools.content.map((t) => t.type));

    /**
     * å¿œç­”å‡¦ç†ã¨ãƒ„ãƒ¼ãƒ«ãƒ»ã‚³ãƒ¼ãƒ«ã®å‡¦ç†
     */
    const finalText: string[] = [];
    const assistantMessageContent: any[] = [];
    const toolCalls: ToolUseBlock[] = [];

    for (const content of selectTools.content) {
      if (content.type === "text") {
        // é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã®å ´åˆ
        finalText.push(content.text);
        assistantMessageContent.push(content);
      } else if (content.type === "tool_use") {
        // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã®å ´åˆ
        toolCalls.push(content);
        assistantMessageContent.push(content);
      }
    }

    // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ãŒã‚ã‚‹å ´åˆã®å‡¦ç†
    if (toolCalls.length != 0) {
      // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã®çµæœã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¨˜éŒ²
      formattedMessages.push({
        role: "assistant",
        content: assistantMessageContent,
      });

      // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
      for (const toolCall of toolCalls) {
        const result = await client.callTool({
          name: toolCall.name,
          arguments: toolCall.input as { [x: string]: unknown },
        });
        const keys = Object.keys(toolCall.input as object);
        const keys2 = Object.keys(result.content as object);
        console.log("ğŸ”¨ åå‰:" + toolCall.name);
        console.log("ğŸ”¨ å› æ•°:" + keys);
        console.log("ğŸ”¨ çµæœ:" + JSON.stringify(result.content));

        formattedMessages.push({
          role: "user",
          content: [
            {
              type: "tool_result",
              tool_use_id: toolCall.id,
              content: result.content,
            },
          ],
        });

        // ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã®çµæœã‚’LLMã«æ¸¡ã™
        const response = await anthropic.messages.create({
          model: "claude-3-5-haiku-latest",
          max_tokens: 1000,
          messages: formattedMessages,
          tools: availableTools,
        });
        console.log(
          "âœ… ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã®çµæœ:",
          response.content.map((t) => t.type)
        );

        finalText.push(
          ...response.content
            .filter((c) => c.type === "text")
            .map((c) => c.text)
        );
        console.log("âœ… æœ€çµ‚ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã®çµæœ:", finalText);
        break;
      }
    }

    /**
     * ãƒ•ã‚§ã‚¤ã‚¯ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ãã®ã¾ã¾å¿œç­”ã‚’é€ä¿¡
     */
    const fakeModel = new FakeListChatModel({
      responses: [finalText.join("\n")],
    });
    const prompt = PromptTemplate.fromTemplate("TEMPLATE1");
    const chain = prompt.pipe(fakeModel);
    const stream = await chain.invoke({});

    return new Response(JSON.stringify(stream));
  } catch (error) {
    if (error instanceof Error) {
      console.log(error);
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 502,
      headers: { "Content-Type": "application/json" },
    });
  }
}
